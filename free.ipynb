{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Made With üíì By - [Devs Do Code](https://www.youtube.com/channel/@devsdocode)\n",
    "\n",
    "- **LinkedIn**: [https://www.linkedin.com/in/developer-sreejan](https://www.linkedin.com/in/developer-sreejan)\n",
    "- **YouTube Channel**: [https://www.youtube.com/@DevsDoCode](https://www.youtube.com/@DevsDoCode)\n",
    "- **Telegram Group**: [https://t.me/devsdocode](https://t.me/devsdocode)\n",
    "- **Discord Server**: [https://discord.gg/hKkTtTfdQH](https://discord.gg/hKkTtTfdQH)\n",
    "- **Instagram**:\n",
    "  - **Personal**: https://www.instagram.com/sree.shades_/\n",
    "  - **Channel**: https://www.instagram.com/devsdocode_/\n",
    "\n",
    "  \n",
    "üîó Support Me:\n",
    "- Buy Me a Coffee: https://buymeacoffee.com/devsdocode\n",
    "- Patreon: https://www.patreon.com/DevsDoCode\n",
    "\n",
    "---\n",
    "\n",
    "üöÄ Dive into the world of coding with [Devs Do Code](https://www.youtube.com/channel/@devsdocode) - where passion meets programming! Make sure to hit that Subscribe button to stay tuned for exciting content! üòä‚ú®\n",
    "\n",
    "**Pro Tip:** For optimal performance and a seamless experience, we recommend using the default library versions demonstrated in this demo. Your coding journey just got even better! Happy coding! üñ•Ô∏èüíª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup and Configuration\n",
    "This notebook demonstrates the integration with various AI models through the OpenAI API interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# Set up API key and base URL\n",
    "API_KEY = \"Watch the Complete Video to Get the API Key. Please it is a small Request!!\"\n",
    "BASE_URL = \"https://api.ddc.xiolabs.xyz/v1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available Models\n",
    "Let's first list all available models we can access through the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Listing All Models ---\n",
      "\n",
      "provider-1/gemini-1.5-flash-8b-exp-0827\n",
      "provider-1/gemini-1.5-flash-8b-001\n",
      "provider-1/gemini-2.0-flash-exp\n",
      "provider-1/gemini-2.0-flash-thinking-exp-1219\n",
      "provider-1/gpt-3.5\n",
      "provider-1/gpt-4\n",
      "provider-1/gpt-4o-mini\n",
      "provider-1/gpt-4o\n",
      "provider-1/pixtral-124b\n",
      "provider-2/gpt-4\n",
      "provider-2/gpt-4-turbo\n",
      "provider-2/gpt-3.5\n",
      "provider-2/gpt-3.5-turbo\n",
      "provider-2/llama-3-8b\n",
      "provider-2/llama-3.1-70b\n",
      "provider-2/gemma-2-27b\n",
      "provider-2/mistral-large\n",
      "provider-3/mistral-nemo\n",
      "provider-3/gpt-4o-mini\n",
      "provider-3/llama-3.3-70b\n",
      "provider-3/qwen-2.5-72b\n",
      "provider-3/qwen-2.5-coder-32b\n",
      "provider-3/unity\n",
      "provider-3/evil\n",
      "provider-3/deepseek-v3\n",
      "flux-dev\n",
      "sdxl-turbo\n",
      "flux-schnell\n",
      "provider-4/gpt-4o\n",
      "provider-4/gpt-4o-mini\n",
      "provider-4/Phi-3.5-MoE-instruct\n",
      "provider-4/Phi-3.5-mini-instruct\n",
      "provider-4/Phi-3-medium-128k-instruct\n",
      "provider-4/Cohere-command-r-plus-08-2024\n",
      "provider-4/Llama-3.2-11B-Vision-Instruct\n",
      "provider-4/Llama-3.2-90B-Vision-Instruct\n",
      "provider-4/Llama-3.3-70B-Instruct\n",
      "provider-4/Mistral-Large-2411\n",
      "provider-4/Codestral-2501\n",
      "provider-4/text-embedding-3-large\n",
      "provider-4/text-embedding-3-small\n",
      "provider-5/qwen-2.5-72b\n",
      "provider-5/codellama-34b\n",
      "provider-5/gemma-2-27b-it\n",
      "provider-5/phi-3.5-mini\n",
      "provider-5/qwen-2.5-coder-32b\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Listing All Models ---\\n\")\n",
    "\n",
    "try:\n",
    "    models = client.models.list().data\n",
    "    for model in models:\n",
    "        print(model.id)\n",
    "except Exception as e:\n",
    "    print(\"Error listing models:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provider 1 Testing\n",
    "### Features:\n",
    "- ‚úÖ Text Generation\n",
    "- ‚úÖ Vision Capabilities (Image Analysis)\n",
    "- ‚ùå Function Calling\n",
    "\n",
    "Testing basic text completion and vision capabilities using Provider 1's models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text completion response:\n",
      "ChatCompletion(id='chatcmpl-6647cbac-c9f5-4fab-8dca-3024bd0dc1e6', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737236052, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=29, prompt_tokens=13, total_tokens=42, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Provider 1 Code\n",
    "# Supports text input and output, and vision capabilities\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Text completion test\n",
    "try:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"provider-1/gpt-4o\",  # Change to any other model under provider-1 if needed\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Hello, how are you today?\"}\n",
    "        ]\n",
    "    )\n",
    "    print(\"Text completion response:\")\n",
    "    print(completion)\n",
    "except Exception as e:\n",
    "    print(\"Error during text completion:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vision capabilities (image input) response:\n",
      "ChatCompletion(id='chatcmpl-c3fc5c2b-5559-4eb3-9398-2036f1a64565', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The image shows a wooden boardwalk path cutting through a lush, green meadow or field. The sky above is bright blue with a few scattered clouds, creating a peaceful and serene atmosphere. The path leads toward the horizon, flanked by tall grass and some bushes or small trees.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737236065, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=69, prompt_tokens=44, total_tokens=113, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "# Vision capabilities test (image input)\n",
    "try:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"provider-1/gpt-4o\",  # Ensure the model supports vision capabilities\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"What's in this image?\"},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "                        }\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=300,\n",
    "    )\n",
    "    print(\"Vision capabilities (image input) response:\")\n",
    "    print(completion)\n",
    "except Exception as e:\n",
    "    print(\"Error during vision capabilities test:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provider 2 Testing\n",
    "### Features:\n",
    "- ‚úÖ Text Generation\n",
    "- ‚ùå Vision Capabilities\n",
    "- ‚ùå Function Calling\n",
    "\n",
    "Testing text generation capabilities using Provider 2's models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Testing Provider 2 ---\n",
      "\n",
      "Text completion response:\n",
      "ChatCompletion(id='chatcmpl-None', choices=[Choice(finish_reason=None, index=0, logprobs=None, message=ChatCompletionMessage(content='A massive error occured, please try again a few moments later,', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737236118, model='gpt-4-turbo', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=15, prompt_tokens=10, total_tokens=25, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Provider 2 Code\n",
    "# Supports text input and output\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n--- Testing Provider 2 ---\\n\")\n",
    "\n",
    "# Text completion test\n",
    "try:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"provider-2/gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Can you explain how photosynthesis works?\"}\n",
    "        ]\n",
    "    )\n",
    "    print(\"Text completion response:\")\n",
    "    print(completion)\n",
    "except Exception as e:\n",
    "    print(\"Error during text completion:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provider 3 Testing\n",
    "### Features:\n",
    "- ‚úÖ Text Generation\n",
    "- ‚ùå Vision Capabilities\n",
    "- ‚ùå Function Calling\n",
    "\n",
    "Testing text generation capabilities using Provider 3's models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Testing Provider 3 ---\n",
      "\n",
      "Text completion response:\n",
      "ChatCompletion(id='chatcmpl-441483', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Once upon a time in the Kingdom of Eldoria, there lived a brave knight named Sir Cedric. Known for his unwavering courage and strong moral compass, he was beloved by the people and feared by his enemies.\\n\\nOne day, a dark sorceress named Malvina unleashed a terrifying dragon upon the kingdom, demanding tribute in exchange for peace. The king, desperate to protect his subjects, summoned Sir Cedric. Without hesitation, Cedric agreed to face the beast, knowing the risk but driven by his duty to defend Eldoria.\\n\\nArmed with his enchanted sword and shield, Sir Cedric rode out to the fiery lair of the dragon. As he approached, the ground trembled and flames spewed forth from the dragon's mouth. The knight stood tall and called upon the strength of his ancestors. With a deep breath, he charged at the beast, dodging flames and slashing with precision.\\n\\nThe battle raged on, and Cedric‚Äôs spirit never wavered despite the dragon's size and fury. With a final, powerful thrust, he drove his sword deep into the heart of the beast, vanquishing it once and for all. The kingdom erupted in cheers as the skies cleared, and freedom was restored.\\n\\nReturning home, Sir Cedric was hailed as a hero. But he humbly believed that true bravery lay not in vanquishing foes alone, but in protecting the innocent. From that day forward, Cedric continued to fight for justice, ensuring that the light of Eldoria would shine brightly for all.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737236153, model='gpt-4o-mini', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=312, prompt_tokens=10, total_tokens=322, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Provider 3 Code\n",
    "# Supports text input and output\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n--- Testing Provider 3 ---\\n\")\n",
    "\n",
    "# Text completion test\n",
    "try:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"provider-3/gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Tell me a short story about a brave knight.\"}\n",
    "        ]\n",
    "    )\n",
    "    print(\"Text completion response:\")\n",
    "    print(completion)\n",
    "except Exception as e:\n",
    "    print(\"Error during text completion:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provider 4 Testing\n",
    "### Features:\n",
    "- ‚úÖ Text Generation\n",
    "- ‚úÖ Vision Capabilities\n",
    "- ‚úÖ Function Calling\n",
    "\n",
    "Testing comprehensive capabilities including text generation, vision analysis, and function calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text completion response:\n",
      "ChatCompletion(id='chatcmpl-chatcmpl-ArAmZNIo5PYfbKFHIqERh71TEdwK6', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The capital of France is **Paris**.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737236195, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=8, prompt_tokens=7, total_tokens=15, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Provider 4 Code\n",
    "# Supports everything: text input/output, vision capabilities, function calling\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Text completion test\n",
    "try:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"provider-4/gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"What's the capital of France?\"}\n",
    "        ]\n",
    "    )\n",
    "    print(\"Text completion response:\")\n",
    "    print(completion)\n",
    "except Exception as e:\n",
    "    print(\"Error during text completion:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vision capabilities (image input) response:\n",
      "ChatCompletion(id='chatcmpl-chatcmpl-ArAmjlbYri3VoXPUsaEklO9hqstDf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='This image depicts a scenic outdoor setting featuring a wooden boardwalk or pathway cutting through a lush grassy field. The field is surrounded by greenery, including bushes and trees in the distance. The sky above is bright and expansive, with a mixture of blue hues and soft clouds, creating a peaceful and serene atmosphere.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737236206, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=82, prompt_tokens=1, total_tokens=83, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "# Vision capabilities test (image input)\n",
    "try:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"provider-4/gpt-4o\",  # Ensure the model supports vision capabilities\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"What's in this image?\"},\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "                        }\n",
    "                    },\n",
    "                ],\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=500,\n",
    "    )\n",
    "    print(\"Vision capabilities (image input) response:\")\n",
    "    print(completion)\n",
    "except Exception as e:\n",
    "    print(\"Error during vision capabilities test:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function calling response:\n",
      "ChatCompletion(id='chatcmpl-chatcmpl-ArAmzPNpPM2wQTdvL6ylWYoC5wDE2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm unable to provide real-time weather updates since my information doesn't access live data or the internet. I recommend checking a reliable weather website or app like [Weather.com](https://weather.com) or a similar source for the most current information about Boston's weather today.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737236222, model='gpt-4o', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=72, prompt_tokens=10, total_tokens=82, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "# Function calling test\n",
    "try:\n",
    "    tools = [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                        },\n",
    "                        \"required\": [\"location\"],\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston today?\"}]\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"provider-4/gpt-4o\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    temperature=0.9,\n",
    "    tool_choice=\"auto\"\n",
    "        )\n",
    "    print(\"Function calling response:\")\n",
    "    print(completion)\n",
    "except Exception as e:\n",
    "    print(\"Error during function calling test:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provider 5 Testing\n",
    "### Features:\n",
    "- ‚úÖ Text Generation\n",
    "- ‚ùå Vision Capabilities\n",
    "- ‚ùå Function Calling\n",
    "\n",
    "Testing text generation capabilities using Provider 5's models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Testing Provider 5 ---\n",
      "\n",
      "Text completion response:\n",
      "ChatCompletion(id='chatcmpl-', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='Of course! Here\\'s one for the books:\\n  Why did mathematics make such an odd couple with philosophy at school dances back in ancient Greece?: Because philosophers had no problem solving complex problems, while mathematicians couldn‚Äôt seem to grasp their own equations‚Äîthey kept adding \"basics\" like axioms and proofs without ever arriving anywhere. Plus they always thought there were too many variables involved ‚Äì literally talking about everything from logic symbols down through infinity... So it was hard when all anyone wanted is simple arithmetic or even better - just some harmonious rhythm of numbers that could sync up properly on both sides (and not endless debates)! But hey let us remember; every great thinker needs someone who can help balance out those heavy-dutying concepts so life doesn‚ÄòT get as complicated than necessary ‚Äî enter our heroes here today friends\\u200a(who aren¬¥ts lost among abstract ideas), bringing laughter into spaces where only serious minds used be dwellin\\'. Have fun unravelng this intellectual comedy duo tale next time around your academic party scene everyone gather \\'round now‚Ä¶ ready listen close because I got more jokes coming right along besides these tales filled full oxygen perhaps taking them over head above clouds allowing sunshine streams shining brightly revealing why must we embrace humor amidst rigorous studies after long night sessions spent contemplating deep questions under starlit skies don\\'\\' tcha know what else makes learning exciting apart form creativity itself ? Well its comedic relief surely helps lighten mood & rejuvenate tired brains eager craving new discoverys often hidden behind monotone lectures left undisturbed due lackluster teaching methods causing drought within young curious spirits thirstier still despite water supplied generously by textbooks aimed sole provide nourishment never intended merely serving purpose hindering growth stunting development prevent potential blooming genius yet imagine if instead professors started sprinkling punny remarks throughout curriculum encouragingly stirring enthusiasm amongst students motivation revived once again flushing away cobweb boredom remnants lingely attached since childhood days sitting quietly listening attentively hoping knowledge would eventually seep slowly absorbed gradually transformative understanding finally reaching deeper layers penetrated previously obscured thereby enabling critical thinking skills expandable beyond boundaries forever changing trajectory towards success await excitement future holds promise oh yes indeed glad', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1737236278, model='phi-3.5-mini', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=644, prompt_tokens=5, total_tokens=649, completion_tokens_details=None, prompt_tokens_details=None))\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Provider 5 Code\n",
    "# Supports text input and output\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n--- Testing Provider 5 ---\\n\")\n",
    "\n",
    "# Text completion test\n",
    "try:\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"provider-5/phi-3.5-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Can you tell me a joke?\"}\n",
    "        ]\n",
    "    )\n",
    "    print(\"Text completion response:\")\n",
    "    print(completion)\n",
    "except Exception as e:\n",
    "    print(\"Error during text completion:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Generation Testing\n",
    "### Using Flux Dev Model\n",
    "Testing image generation capabilities using the Flux Dev model.\n",
    "- Model: `flux-dev`\n",
    "- Capability: Image Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Testing Flux Dev Model ---\n",
      "\n",
      "Error during image generation: Error code: 500 - {'error': {'message': 'An internal server error occurred', 'type': 'internal_server_error', 'param': None, 'code': None}}\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# Flux Dev Model Test\n",
    "# This is an image generation model\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "print(\"\\n\\n--- Testing Flux Dev Model ---\\n\")\n",
    "\n",
    "try:\n",
    "    response = client.images.generate(\n",
    "        model=\"flux-dev\",\n",
    "        prompt=\"A colorful sunset over a mountain range\",\n",
    "        size=\"1024x1024\"\n",
    "    )\n",
    "    print(\"Image generation response:\")\n",
    "    print(response)\n",
    "except Exception as e:\n",
    "    print(\"Error during image generation:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status Uptime\n",
    "Check this - https://status.ddc.xiolabs.xyz/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
